{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Solution\n",
    "This script will attempt to solve the problem explained in the `TODO.md` file. It will be focused only in the first section, \"Objetivo 1: lectura y tratamiento\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Download the data\n",
    "First we will try to download the raw data from 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD PUNTO_MUESTREO   ANO  MES  D01  \\\n",
      "0         28         79         4         1  28079004_1_38  2018    1  1.0   \n",
      "1         28         79         4         1  28079004_1_38  2018    2  5.0   \n",
      "2         28         79         4         1  28079004_1_38  2018    3  1.0   \n",
      "3         28         79         4         1  28079004_1_38  2018    4  2.0   \n",
      "4         28         79         4         1  28079004_1_38  2018    5  2.0   \n",
      "\n",
      "  V01  D02  ...  D27  V27  D28  V28  D29  V29  D30  V30  D31  V31  \n",
      "0   V  1.0  ...  2.0    V  2.0    V  6.0    V  5.0    V  6.0    V  \n",
      "1   V  3.0  ...  3.0    V  2.0    V  0.0    N  0.0    N  0.0    N  \n",
      "2   V  2.0  ...  2.0    V  4.0    V  2.0    V  2.0    V  2.0    V  \n",
      "3   V  3.0  ...  1.0    V  2.0    V  2.0    V  2.0    V  0.0    N  \n",
      "4   V  2.0  ...  2.0    V  2.0    V  3.0    V  2.0    V  2.0    V  \n",
      "\n",
      "[5 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "url = r'https://datos.madrid.es/egob/catalogo/201410-7775096-calidad-aire-diario.csv'\n",
    "# sep specifies the column delimiter\n",
    "df = pd.read_csv(url, sep=';')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Format the data\n",
    "Once we have all the raw data in a `dataframe` we can focus on the transformations for making it's use easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Remove unwanted data\n",
    "We will remove all data that is not related with NO2, We only care about all the data with Magnitud = 08. Once the data is removed, the column no longer makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting our MAGNITUD and Removing the column MAGNITUD:\n",
    "nitrogen_dioxide_df = df.loc[df['MAGNITUD'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nitrogen_dioxide_df = nitrogen_dioxide_df.drop(columns=['MAGNITUD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PROVINCIA  MUNICIPIO  ESTACION PUNTO_MUESTREO   ANO  MES   D01 V01   D02  \\\n",
      "36         28         79         4   28079004_8_8  2018    1  21.0   V  29.0   \n",
      "37         28         79         4   28079004_8_8  2018    2  58.0   V  47.0   \n",
      "38         28         79         4   28079004_8_8  2018    3  35.0   V  53.0   \n",
      "39         28         79         4   28079004_8_8  2018    4  38.0   V  40.0   \n",
      "40         28         79         4   28079004_8_8  2018    5  25.0   V  29.0   \n",
      "\n",
      "   V02  ...   D27 V27   D28 V28   D29 V29   D30 V30   D31 V31  \n",
      "36   V  ...  26.0   V  22.0   V  67.0   V  61.0   V  74.0   V  \n",
      "37   V  ...  55.0   V  52.0   V   0.0   N   0.0   N   0.0   N  \n",
      "38   V  ...  40.0   V  41.0   V  14.0   V   9.0   V  16.0   V  \n",
      "39   V  ...  26.0   V  14.0   V  13.0   V  24.0   V   0.0   N  \n",
      "40   V  ...  26.0   V  32.0   V  47.0   V  35.0   V  31.0   V  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "print(nitrogen_dioxide_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also remove the V columns. We can verify each column and mark as NaN all the values that are not verified. After this, V column will be redundant so we will remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step will be to define a function that can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_measure(measures, verifications):\n",
    "    \"\"\"\n",
    "     Checks if a given measurement is verified. \n",
    "     It builds a new column were all values not verified are change to NaN\n",
    "    Args:\n",
    "        measures: The raw measures that might be verified or not\n",
    "        verifications:  The verification data.\n",
    "        A letter 'V' means verified and 'N' means NOT verified\n",
    "\n",
    "    Returns:\n",
    "        The corrected column with only verified data and NaNs \n",
    "        in non verified measurements.\n",
    "\n",
    "    \"\"\"\n",
    "    corrected = measures.copy()\n",
    "    for index, measure in measures.iteritems():\n",
    "        if 'V' in verifications[index]:\n",
    "            corrected[index] = measure\n",
    "        elif 'N' in verifications[index]:\n",
    "            corrected[index] = np.nan\n",
    "        else:\n",
    "            print(\"A measure was neither verified nor unverified.\")\n",
    "\n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the function we will need all the measurements and verifications isolated and a df to edit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample value that we now should change from 0, N to NaN\n",
      "0.0\n",
      "N\n"
     ]
    }
   ],
   "source": [
    "d_df = nitrogen_dioxide_df[nitrogen_dioxide_df.columns[\n",
    "    pd.Series(nitrogen_dioxide_df.columns).str.startswith('D')]]\n",
    "v_df = nitrogen_dioxide_df[nitrogen_dioxide_df.columns[\n",
    "    pd.Series(nitrogen_dioxide_df.columns).str.startswith('V')]]\n",
    "\n",
    "print(\"Sample value that we now should change from 0, N to NaN\")\n",
    "print(d_df['D29'][37])\n",
    "print(v_df['V29'][37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe to edit (avoiding warning):\n",
    "corrected_measures = d_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed with the measurement correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_d, column_v in zip(d_df.columns, v_df.columns):\n",
    "    corrected_measures[column_d] = verify_measure(d_df[column_d], v_df[column_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If this has worked now 'corrected_measures['D29'][37]' should be NaN: \n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(\"If this has worked now 'corrected_measures['D29'][37]' should be NaN: \")\n",
    "print(corrected_measures['D29'][37])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to build our final df without v and with verified measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PROVINCIA  MUNICIPIO  ESTACION PUNTO_MUESTREO   ANO  MES   D01   D02  \\\n",
      "36         28         79         4   28079004_8_8  2018    1  21.0  29.0   \n",
      "37         28         79         4   28079004_8_8  2018    2  58.0  47.0   \n",
      "38         28         79         4   28079004_8_8  2018    3  35.0  53.0   \n",
      "39         28         79         4   28079004_8_8  2018    4  38.0  40.0   \n",
      "40         28         79         4   28079004_8_8  2018    5  25.0  29.0   \n",
      "\n",
      "     D03   D04  ...   D22   D23   D24   D25   D26   D27   D28   D29   D30  \\\n",
      "36  35.0  26.0  ...  54.0  57.0  62.0  46.0  38.0  26.0  22.0  67.0  61.0   \n",
      "37  41.0  31.0  ...  54.0  60.0  63.0  66.0  76.0  55.0  52.0   NaN   NaN   \n",
      "38  27.0  25.0  ...  48.0  51.0  14.0  25.0  50.0  40.0  41.0  14.0   9.0   \n",
      "39  24.0  21.0  ...  46.0  50.0  53.0  56.0  45.0  26.0  14.0  13.0  24.0   \n",
      "40  42.0  41.0  ...  49.0  45.0  41.0  38.0  28.0  26.0  32.0  47.0  35.0   \n",
      "\n",
      "     D31  \n",
      "36  74.0  \n",
      "37   NaN  \n",
      "38  16.0  \n",
      "39   NaN  \n",
      "40  31.0  \n",
      "\n",
      "[5 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "no2_no_v_df = nitrogen_dioxide_df.drop(columns=(list(d_df.columns) + list(v_df.columns)))\n",
    "no2_no_v_df = pd.concat([no2_no_v_df, corrected_measures], axis=1)\n",
    "\n",
    "print(no2_no_v_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done! We have removed all the obviously redundant information! ðŸ™‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 The not that obvious formatting.\n",
    "\n",
    "By looking at the data I have multiple ideas of how to process it or make it more usefull but I think at this point I would talk to the people that will be using the data to get more info on **how** they will be using it.\n",
    "\n",
    "Coding this might be time consuming, I will be explaining it instead. If I have some extra time after the other sections I will tackle it and see how far I can get.\n",
    "\n",
    "### Examples\n",
    "1. Clearly we need some kind of timestamp to make the processing much easier. I would change ANO, MES and D* columns for only one timestamp column using [rfc3339](https://tools.ietf.org/html/rfc3339) format. In real life choosing a timestamp format is not that easy, some situations I have seen:\n",
    " * Multiple timestamp formats at the same time in one application because they were through a transition.\n",
    " * Systems using timestamps in String format (they said it increased simple query speed but I was not that sure...) requiring a conversion to a date/time format for complex queries.\n",
    " * Systems using Local time instead of UTC, in this cases the client thinks that is executing a task at a certain moment but the server might be logging that it happend an hour later, ...\n",
    "2. The column PUNTO_MUESTREO is redundant but we don't know how we should show the weather station info. If It was my decision I would choose one of the following options:\n",
    " * Substitute the numbers of PROVINCIA and MUNICIPIO for its names, leave the stations as numbers and remove the PUNTO_MUESTRO column. This would simplify the querying process and save time looking at the tables with that info for every query.\n",
    " * Get all GPS locations of each station and update ESTACION with this coordinates. Then I would remove PROVINCIA MUNICIPIO and PUNTO_MUESTREO. Probably if you want to draw an interactive map it is easier with GPS locations.\n",
    "3. There is also a general problem with how the info is organized. It is not natural because there are a lot of columns and some NaN values could be avoided. For example February 31 will always be NaN for all stations.\n",
    "\n",
    "If I took care of all this formatting on my own, the data would be organized like this:\n",
    "\n",
    "| TimeStamp            | WeatherStation    | No2  |\n",
    "| -------------------- | ----------------- | ---- |\n",
    "| 2018-01-01T08:00:00Z | +48.52+002.20     | 21.0 |\n",
    "| 2018-01-02T08:00:00Z | +48.8577+002.295  | 29.0 |\n",
    "| 2018-01-03T08:00:00Z | +40.75-074.00     | 35.0 |\n",
    "| 2018-01-04T08:00:00Z | +40.6894-074.0447 | 26.0 |\n",
    "| 2018-01-05T08:00:00Z | +40.4165-3.70256  | 54.0 |\n",
    "\n",
    "If we wanted it to also be easier to use we could create another table to store data about the Weather stations and with a simple join you could search No2 values based on MUNICIPIO for example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper explanation of Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altering the whole table structure is going to take a few steps I will try to describe them in detail:\n",
    "1. Creating the destination table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>no2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>28079008_8_8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>28079011_8_8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>28079016_8_8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "      <td>28079017_8_8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  PROVINCIA  MUNICIPIO  ESTACION PUNTO_MUESTREO  no2\n",
       "0 2018-01-01         28         79         4   28079004_8_8  NaN\n",
       "1 2018-01-01         28         79         8   28079008_8_8  NaN\n",
       "2 2018-01-01         28         79        11   28079011_8_8  NaN\n",
       "3 2018-01-01         28         79        16   28079016_8_8  NaN\n",
       "4 2018-01-01         28         79        17   28079017_8_8  NaN"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we create a table with all the possible dates for a measurement:\n",
    "dates = pd.date_range(start='1/1/2018', periods=365, freq='D',\n",
    "                      name='date').to_frame()\n",
    "dates.head()\n",
    "# Then a table with all possible pollution stations and it's data:\n",
    "station_data = no2_no_v_df[\n",
    "    ['PROVINCIA', 'MUNICIPIO', 'ESTACION', 'PUNTO_MUESTREO']].drop_duplicates()\n",
    "station_data.head()\n",
    "# Now we have to join them because we will have one daily measurement from each stations.\n",
    "# We cannot simply merge de dataframes becuase they do not have a matching column.\n",
    "# Since the key of the resulting dataframe will be the combination of the keys \n",
    "# of both original dataframes we can simply create a temporary column and do the join\n",
    "dates['tmp'] = 1\n",
    "station_data['tmp'] = 1\n",
    "new_format_df = pd.merge(dates, station_data, on='tmp').drop('tmp', axis=1)\n",
    "# To finish the destination table we will simply add \n",
    "# a no2 column for the nitorgen dioxide values with all nans (for the moment)\n",
    "new_format_df['no2'] = np.nan\n",
    "# Using a 30 for the head might be more enlightening\n",
    "# new_format_df.head(30)\n",
    "new_format_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Populate destination table with original table's data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>no2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>4</td>\n",
       "      <td>28079004_8_8</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>28079008_8_8</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>28079011_8_8</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>16</td>\n",
       "      <td>28079016_8_8</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "      <td>28079017_8_8</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  PROVINCIA  MUNICIPIO  ESTACION PUNTO_MUESTREO   no2\n",
       "0 2018-01-01         28         79         4   28079004_8_8  21.0\n",
       "1 2018-01-01         28         79         8   28079008_8_8  47.0\n",
       "2 2018-01-01         28         79        11   28079011_8_8  24.0\n",
       "3 2018-01-01         28         79        16   28079016_8_8  31.0\n",
       "4 2018-01-01         28         79        17   28079017_8_8  22.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for row in new_format_df.itertuples():\n",
    "    # Define the key variables in each row:\n",
    "    year = row.date.year\n",
    "    month = row.date.month\n",
    "    day = row.date.day\n",
    "    day_formatted = 'D' + f'{day:02}'\n",
    "    \n",
    "    # Extract relevant value from origin table:\n",
    "    # We obtain the day column and filter by 'year', 'month' and 'PUNTO_MUESTREO'\n",
    "    no2_value = no2_no_v_df[day_formatted][\n",
    "        (no2_no_v_df['PUNTO_MUESTREO'] == row.PUNTO_MUESTREO) &\n",
    "        (no2_no_v_df['MES'] == month) &\n",
    "        (no2_no_v_df['ANO'] == year)].item()\n",
    "    \n",
    "    # Write relevant data retrieved from origin table to destination table:\n",
    "    # we write the 'no2' column from the row with that timestamp and that 'PUNTO_MUESTREO'\n",
    "    new_format_df.loc[\n",
    "            (new_format_df['date'] == datetime(year=year, month=month, day=day)) &\n",
    "            (new_format_df['PUNTO_MUESTREO'] == row.PUNTO_MUESTREO)\n",
    "            , 'no2'] = no2_value\n",
    "    \n",
    "new_format_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Store the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we will be having a lot of rows and a relatively simple data strcuture. I would clearly go for a SQL approach, we do not need the flexibility of a NonSQL database such as Mongo. We need to be able to store the data as efficiently as possible and I know from experience that **PostgreSQL** is easy to use, quick and efficient.\n",
    "\n",
    "The problem that we might have with **PostgreSQL** is that it is not natively distributed so it is not that good working in a lot of nodes simultaneously. As a consequence **PostgreSQL** cannot scale horizontally, having a huge database on the cloud might be expensive.\n",
    "\n",
    "For the moment I would go with **PostgreSQL** but always keeping in mind those problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
